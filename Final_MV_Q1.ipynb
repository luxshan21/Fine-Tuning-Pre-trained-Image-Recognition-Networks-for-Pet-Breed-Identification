{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: EN4553 (Machine Vision)"
      ],
      "metadata": {
        "id": "qkoPU7ldK-ov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18V2xgtLK934"
      },
      "outputs": [],
      "source": [
        "# !wget https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz\n",
        "# !tar -xzf images.tar.gz\n",
        "# !wget https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz\n",
        "# !tar -xzf annotations.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file in colab to test full sketch at once\n",
        "!python3 q1_knn_classifier.py"
      ],
      "metadata": {
        "id": "yPBavOrsBhtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score"
      ],
      "metadata": {
        "id": "JBqdtxRGtSnZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader(dir='data',batch_size=32):\n",
        "  # Define the transformation to be applied to the images\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((224, 224)),\n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  # Create the dataset\n",
        "  train_data = OxfordIIITPet(root=dir+\"/train\", split='trainval'  , transform=transform,download=True)\n",
        "  test_data = OxfordIIITPet(root=dir+\"/test\", split='test'  , transform=transform,download=True)\n",
        "\n",
        "  # Create a data loader\n",
        "  train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "  test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  return train_data_loader, test_data_loader"
      ],
      "metadata": {
        "id": "frrcuFU2t8g4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader, test_data_loader = data_loader()"
      ],
      "metadata": {
        "id": "xbZlXRNP_Se6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c906f5-c540-4cc0-e16f-e104e2172356"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to data/train/oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 791918971/791918971 [00:39<00:00, 20297482.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/train/oxford-iiit-pet/images.tar.gz to data/train/oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to data/train/oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19173078/19173078 [00:02<00:00, 9071447.26it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/train/oxford-iiit-pet/annotations.tar.gz to data/train/oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to data/test/oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 791918971/791918971 [00:38<00:00, 20839738.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/test/oxford-iiit-pet/images.tar.gz to data/test/oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to data/test/oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19173078/19173078 [00:02<00:00, 7964589.33it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/test/oxford-iiit-pet/annotations.tar.gz to data/test/oxford-iiit-pet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_embeddings(data_loader, device):\n",
        "    # Load pre-trained ResNet-50 model\n",
        "    resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "    # Remove the last classifier layer (fully connected layer)\n",
        "    model = nn.Sequential(*list(resnet50.children())[:-1])\n",
        "    model.eval()\n",
        "\n",
        "    # Move the model to GPU if available\n",
        "    model.to(device)\n",
        "\n",
        "    # Extract ResNet-50 embeddings and labels\n",
        "    embeddings, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            images, batch_labels = batch\n",
        "            # Move the input images and labels to GPU if available\n",
        "            images, batch_labels = images.to(device), batch_labels.to(device)\n",
        "\n",
        "            batch_embeddings = model(images)\n",
        "            embeddings.append(batch_embeddings)\n",
        "            labels.append(batch_labels)\n",
        "\n",
        "    # Concatenate embeddings and labels\n",
        "    embeddings = torch.cat(embeddings, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "\n",
        "    # Flatten the embeddings\n",
        "    embeddings = embeddings.view(embeddings.size(0), -1)\n",
        "\n",
        "    return embeddings.cpu().numpy(), labels.cpu().numpy()"
      ],
      "metadata": {
        "id": "QuaIUeYz8DnK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and use it, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Embedding find start\")\n",
        "X_train, y_train = find_embeddings(train_data_loader, device)\n",
        "print(\"Training embedding found successfully\")\n",
        "\n",
        "X_test, y_test = find_embeddings(test_data_loader, device)\n",
        "print(\"Test embedding found successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnVa9OFW_XsC",
        "outputId": "a8e01383-f7dc-4509-907f-9da2654aa073"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding find start\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 154MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training embedding found successfully\n",
            "Test embedding found successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LAXKtqriE8S",
        "outputId": "cd712f4f-6010-44f5-fca8-84ca073c98d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train k-NN classifier\n",
        "k = 37\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = knn_classifier.predict(X_test)\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions,average='weighted')\n",
        "recall = recall_score(y_test, predictions,average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ3OCAeyx3sg",
        "outputId": "2e748bf8-7aef-4db3-c4f3-4a06d16928a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8146633960207141\n",
            "Accuracy: 0.8146633960207141\n",
            "Precision: 0.824486255096862\n",
            "Recall: 0.8146633960207141\n"
          ]
        }
      ]
    }
  ]
}